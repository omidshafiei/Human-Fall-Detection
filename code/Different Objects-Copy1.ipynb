{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from scipy import stats\n",
    "from sklearn import svm, datasets , metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 521)\n",
      "(30, 20)\n",
      "(192, 521)\n",
      "(30, 20)\n"
     ]
    }
   ],
   "source": [
    "data1 = np.loadtxt(\"A1.txt\")\n",
    "data2 = np.loadtxt(\"A2.txt\")\n",
    "# data3 = np.loadtxt(\"A3.txt\")\n",
    "# data4 = np.loadtxt(\"A4.txt\")\n",
    "# data5 = np.loadtxt(\"A5.txt\")\n",
    "# data6 = np.loadtxt(\"A6.txt\")\n",
    "# data7 = np.loadtxt(\"A7.txt\")\n",
    "\n",
    "data = np.concatenate((data1,data2))\n",
    "\n",
    "print(data.shape)\n",
    "\n",
    "\n",
    "XTrain = data[:,0:20]\n",
    "yTrain = data[:,520]\n",
    "print(XTrain.shape)\n",
    "\n",
    "Tdata1 = np.loadtxt(\"T1.txt\")\n",
    "Tdata2 = np.loadtxt(\"T2.txt\")\n",
    "# Tdata3 = np.loadtxt(\"T3.txt\")\n",
    "# Tdata4 = np.loadtxt(\"T4.txt\")\n",
    "# Tdata5 = np.loadtxt(\"T5.txt\")\n",
    "# Tdata6 = np.loadtxt(\"T6.txt\")\n",
    "# Tdata7 = np.loadtxt(\"T7.txt\")\n",
    "\n",
    "Tdata = np.concatenate((Tdata1,Tdata2))\n",
    "\n",
    "print(Tdata.shape)\n",
    "\n",
    "\n",
    "XTest = Tdata[:,0:20]\n",
    "yTest = Tdata[:,520]\n",
    "print(XTrain.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from sklearn import preprocessing\n",
    "# import numpy as np\n",
    "# X_scaled = preprocessing.scale(XTrain)\n",
    "# XTrain = X_scaled\n",
    "\n",
    "\n",
    "# TX_scaled = preprocessing.scale(XTest)\n",
    "# XTest = TX_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=10)\n",
    "pca.fit(XTrain)\n",
    "Xproj = pca.fit_transform(XTrain)\n",
    "XTrain = Xproj\n",
    "\n",
    "\n",
    "Tpca = PCA(n_components=10)\n",
    "Tpca.fit(XTest)\n",
    "TXproj = pca.fit_transform(XTest)\n",
    "XTest = TXproj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "# from sklearn.feature_selection import SelectFromModel\n",
    "# XTrain = data[:,0:500]\n",
    "# yTrain = data[:,520]\n",
    "# XTrain.shape\n",
    "\n",
    "# clf = ExtraTreesClassifier()\n",
    "# clf = clf.fit(XTrain, yTrain)\n",
    "# clf.feature_importances_  \n",
    "# # array([ 0.04...,  0.05...,  0.4...,  0.4...])\n",
    "# model = SelectFromModel(clf, prefit=True)\n",
    "# X_new = model.transform(XTrain)\n",
    "# X_new.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "# # Build a forest and compute the feature importances\n",
    "# forest = ExtraTreesClassifier(n_estimators=250,\n",
    "#                               random_state=0)\n",
    "\n",
    "# forest.fit(XTrain, yTrain)\n",
    "# importances = forest.feature_importances_\n",
    "# std = np.std([tree.feature_importances_ for tree in forest.estimators_],\n",
    "#              axis=0)\n",
    "# indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# # Print the feature ranking\n",
    "# print(\"Feature ranking:\")\n",
    "\n",
    "# for f in range(XTrain.shape[1]):\n",
    "#     print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))\n",
    "\n",
    "# # Plot the feature importances of the forest\n",
    "# plt.figure()\n",
    "# plt.title(\"Feature importances\")\n",
    "# plt.bar(range(XTrain.shape[1]), importances[indices],\n",
    "#        color=\"r\", yerr=std[indices], align=\"center\")\n",
    "# plt.xticks(range(XTrain.shape[1]), indices)\n",
    "# plt.xlim([-1, XTrain.shape[1]])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from sklearn.svm import LinearSVC\n",
    "\n",
    "# from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "\n",
    "# XTrain.shape\n",
    "# print(XTrain.shape)\n",
    "\n",
    "# lsvc = LinearSVC(C=0.01, penalty=\"l1\", dual=False).fit(XTrain, yTrain)\n",
    "# model = SelectFromModel(lsvc, prefit=True)\n",
    "# X_new = model.transform(XTrain)\n",
    "# X_new.shape\n",
    "\n",
    "# print(X_new.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# NXTrain = XTrain[:,indices[0:2]]\n",
    "# NXTest = XTest[:,indices[0:2]]\n",
    "# print(NXTrain.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for classifier SVC(C=0.1, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='linear',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False):\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.68      0.52      0.59        96\n",
      "        2.0       0.61      0.76      0.68        96\n",
      "\n",
      "avg / total       0.65      0.64      0.64       192\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[50 46]\n",
      " [23 73]]\n",
      "Classification report for classifier SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='linear',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False):\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.70      0.65      0.67        96\n",
      "        2.0       0.67      0.73      0.70        96\n",
      "\n",
      "avg / total       0.69      0.69      0.69       192\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[62 34]\n",
      " [26 70]]\n",
      "Classification report for classifier SVC(C=1e-05, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='linear',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False):\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.77      0.28      0.41        96\n",
      "        2.0       0.56      0.92      0.70        96\n",
      "\n",
      "avg / total       0.67      0.60      0.55       192\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[27 69]\n",
      " [ 8 88]]\n",
      "Classification report for classifier SVC(C=0.01, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='linear',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False):\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.77      0.28      0.41        96\n",
      "        2.0       0.56      0.92      0.70        96\n",
      "\n",
      "avg / total       0.67      0.60      0.55       192\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[27 69]\n",
      " [ 8 88]]\n",
      "Classification report for classifier SVC(C=0.0001, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='linear',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False):\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.77      0.28      0.41        96\n",
      "        2.0       0.56      0.92      0.70        96\n",
      "\n",
      "avg / total       0.67      0.60      0.55       192\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[27 69]\n",
      " [ 8 88]]\n",
      "Classification report for classifier SVC(C=0.001, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='linear',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False):\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.77      0.28      0.41        96\n",
      "        2.0       0.56      0.92      0.70        96\n",
      "\n",
      "avg / total       0.67      0.60      0.55       192\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[27 69]\n",
      " [ 8 88]]\n"
     ]
    }
   ],
   "source": [
    "# h = .02  # step size in the mesh\n",
    "\n",
    "\n",
    "range_C = {0.00001,0.0001, 0.001,0.01,0.1,1}\n",
    "\n",
    "for C in range_C:\n",
    "    \n",
    "    svc = svm.SVC(kernel='linear', C=C).fit(NXTrain, yTrain)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Now predict the value of the digit on the test data:\n",
    "    expected = yTest\n",
    "    predicted = svc.predict(NXTest)\n",
    "\n",
    "    print(\"Classification report for classifier %s:\\n%s\\n\"\n",
    "          % (svc, metrics.classification_report(expected, predicted)))\n",
    "    print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(expected, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # h = .02  # step size in the mesh\n",
    "\n",
    "\n",
    "# range_Q = {2,3,4,5}\n",
    "# range_C = {0.0001, 0.001,0.01,0.1,1}\n",
    "\n",
    "# for Q in range_Q:\n",
    "#     for C in range_C:\n",
    "\n",
    "#         poly_svc = svm.SVC(kernel='poly', degree=Q, C=C).fit(NXTrain, yTrain)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#         # Now predict the value of the digit on the test data:\n",
    "#         expected = yTest\n",
    "#         predicted = poly_svc.predict(NXTest)\n",
    "\n",
    "#         print(\"Classification report for classifier %s:\\n%s\\n\"\n",
    "#               % (poly_svc, metrics.classification_report(expected, predicted)))\n",
    "#         print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(expected, predicted))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
